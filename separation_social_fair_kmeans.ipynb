{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378e2300-53d2-4897-9ea4-03b633dd6b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22aeb158-c826-478f-a592-c66c001d8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONFIG = {\n",
    "    \"adult\": {\n",
    "        \"csv_path\": \"adult_preprocessed.csv\",\n",
    "        \"feature_cols\": [\n",
    "            \"age\", \"final-weight\", \"education-num\", \"marital-status\",\n",
    "            \"occupation\", \"relationship\", \"capital-gain\",\n",
    "            \"hours-per-week\", \"native-country\", \"income\"\n",
    "        ],\n",
    "        \"sensitive_col\": \"sex\",   # protected attribute\n",
    "        \"k\": 6,\n",
    "        \"tag\": \"adult\",\n",
    "    },\n",
    "    \"bank\": {\n",
    "        \"csv_path\": \"bank_preprocessed.csv\",\n",
    "        \"feature_cols\": [\n",
    "            # TODO: change to the exact columns you use for Bank\n",
    "            \"age\", \"job\", \"marital\", \"education\", \"balance\",\n",
    "            \"housing\", \"loan\", \"campaign\", \"pdays\", \"previous\"\n",
    "        ],\n",
    "        \"sensitive_col\": \"sex\",   # or whatever you use\n",
    "        \"k\": 6,\n",
    "        \"tag\": \"bank\",\n",
    "    },\n",
    "    \"credit\": {\n",
    "        \"csv_path\": \"credit_preprocessed.csv\",\n",
    "        \"feature_cols\": [\n",
    "            # TODO: change to the exact columns you use for Credit\n",
    "            \"LIMIT_BAL\", \"AGE\", \"PAY_0\", \"PAY_2\", \"PAY_3\",\n",
    "            \"PAY_4\", \"PAY_5\", \"PAY_6\", \"BILL_AMT1\", \"BILL_AMT2\"\n",
    "        ],\n",
    "        \"sensitive_col\": \"sex\",\n",
    "        \"k\": 6,\n",
    "        \"tag\": \"credit\",\n",
    "    },\n",
    "    \"student\": {\n",
    "        \"csv_path\": \"student_preprocessed.csv\",\n",
    "        \"feature_cols\": [\n",
    "            # TODO: change to the exact columns you use for Student\n",
    "            \"age\", \"Medu\", \"Fedu\", \"studytime\", \"failures\",\n",
    "            \"famrel\", \"freetime\", \"goout\", \"G1\", \"G2\"\n",
    "        ],\n",
    "        \"sensitive_col\": \"sex\",\n",
    "        \"k\": 6,\n",
    "        \"tag\": \"student\",\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57bd472f-0e62-4396-98d1-72442deb87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset_name: str):\n",
    "    \"\"\"Load dataset, standardize features, and build XA / XB.\"\"\"\n",
    "    cfg = DATASET_CONFIG[dataset_name]\n",
    "    df = pd.read_csv(cfg[\"csv_path\"])\n",
    "\n",
    "    X = df[cfg[\"feature_cols\"]].values\n",
    "    s = df[cfg[\"sensitive_col\"]].values\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    XA = X_scaled[s > 0]\n",
    "    XB = X_scaled[s <= 0]\n",
    "\n",
    "    print(f\"[{dataset_name}] n = {len(X_scaled)}\")\n",
    "    print(f\"[{dataset_name}] |A| = {(s > 0).sum()}, |B| = {(s <= 0).sum()}\")\n",
    "\n",
    "    return X_scaled, XA, XB, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "913e7a8c-355e-47e2-9dfb-677a08336806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _group_masks_from_sets(X, XA, XB):\n",
    "    \"\"\"\n",
    "    Given full dataset X and subsets XA, XB, \n",
    "    return boolean masks inA, inB such that:\n",
    "    inA[i] = True if X[i] ∈ XA\n",
    "    inB[i] = True if X[i] ∈ XB\n",
    "    \"\"\"\n",
    "    Xv  = np.ascontiguousarray(X).view([('', X.dtype)] * X.shape[1]).ravel()\n",
    "    XAv = np.ascontiguousarray(XA).view([('', XA.dtype)] * XA.shape[1]).ravel()\n",
    "    XBv = np.ascontiguousarray(XB).view([('', XB.dtype)] * XB.shape[1]).ravel()\n",
    "    inA = np.in1d(Xv, XAv)\n",
    "    inB = np.in1d(Xv, XBv)\n",
    "    return inA, inB\n",
    "\n",
    "\n",
    "def _assign(X, C):\n",
    "    \"\"\"\n",
    "    Assign each data point in X to its closest cluster center in C.\n",
    "    Returns:\n",
    "        a   : array of cluster indices for each point\n",
    "        d2  : squared distances to all centers\n",
    "    \"\"\"\n",
    "    d2 = np.sum((X[:, None, :] - C[None, :, :]) ** 2, axis=2)\n",
    "    return np.argmin(d2, axis=1), d2\n",
    "\n",
    "\n",
    "def _kmeans_grad(X, C, a):\n",
    "    \"\"\"\n",
    "    Gradient of the standard k-means objective:\n",
    "      1/N Σ ||x - μ_c||²\n",
    "    Returns:\n",
    "        grad, counts, means\n",
    "    \"\"\"\n",
    "    K, D = C.shape\n",
    "    N = len(X)\n",
    "    sums = np.zeros_like(C)\n",
    "    np.add.at(sums, a, X)\n",
    "    counts = np.bincount(a, minlength=K).astype(np.float64).reshape(-1, 1)\n",
    "    means = np.divide(sums, np.maximum(counts, 1.0), where=counts > 0)\n",
    "    grad = 2.0 * counts * (C - means) / N\n",
    "    return grad, counts, means\n",
    "\n",
    "\n",
    "def _group_kmeans_grad(X, C, a, group_mask):\n",
    "    \"\"\"\n",
    "    Group-wise k-means gradient:\n",
    "      1/|G| Σ_{i∈G} ||x - μ_c||²\n",
    "    for a given group G.\n",
    "    Returns:\n",
    "        grad, group_loss\n",
    "    \"\"\"\n",
    "    Xg = X[group_mask]\n",
    "    ag = a[group_mask]\n",
    "    if len(Xg) == 0:\n",
    "        return np.zeros_like(C), 0.0\n",
    "\n",
    "    K, D = C.shape\n",
    "    G = len(Xg)\n",
    "    sums = np.zeros_like(C)\n",
    "    np.add.at(sums, ag, Xg)\n",
    "    counts = np.bincount(ag, minlength=K).astype(np.float64).reshape(-1, 1)\n",
    "    means = np.divide(sums, np.maximum(counts, 1.0), where=counts > 0)\n",
    "    grad = 2.0 * counts * (C - means) / G\n",
    "    loss = np.sum((Xg - C[ag]) ** 2) / G\n",
    "    return grad, loss\n",
    "\n",
    "\n",
    "def _separation_grad_for_group(Gpts, C, eps=1e-12):\n",
    "    \"\"\"\n",
    "    Separation gradient for one group:\n",
    "      1/|G| Σ s(x)^2,\n",
    "    where s(x) is the signed distance to the nearest Voronoi bisector\n",
    "    between the two closest centroids.\n",
    "    Returns:\n",
    "        grad, separation_value\n",
    "    \"\"\"\n",
    "    if len(Gpts) == 0:\n",
    "        return np.zeros_like(C), 0.0\n",
    "\n",
    "    # Distances to all centers\n",
    "    d2 = np.sum((Gpts[:, None, :] - C[None, :, :]) ** 2, axis=2)\n",
    "    m1_idx = np.argmin(d2, axis=1)\n",
    "    d2_mask = d2.copy()\n",
    "    d2_mask[np.arange(len(Gpts)), m1_idx] = np.inf\n",
    "    m2_idx = np.argmin(d2_mask, axis=1)\n",
    "\n",
    "    m1, m2 = C[m1_idx], C[m2_idx]\n",
    "    m = 0.5 * (m1 + m2)\n",
    "    v = m2 - m1\n",
    "    vn = np.linalg.norm(v, axis=1, keepdims=True)\n",
    "    vhat = v / np.maximum(vn, eps)\n",
    "\n",
    "    s = np.sum((Gpts - m) * vhat, axis=1)\n",
    "    Px = (Gpts - m) - vhat * s[:, None]\n",
    "\n",
    "    grad_m1 = (2.0 * s)[:, None] * (-(Px / np.maximum(vn, eps)) - 0.5 * vhat)\n",
    "    grad_m2 = (2.0 * s)[:, None] * ((Px / np.maximum(vn, eps)) - 0.5 * vhat)\n",
    "\n",
    "    K, D = C.shape\n",
    "    grad = np.zeros_like(C)\n",
    "    np.add.at(grad, m1_idx, grad_m1)\n",
    "    np.add.at(grad, m2_idx, grad_m2)\n",
    "    grad /= len(Gpts)\n",
    "\n",
    "    val = np.mean(s ** 2)\n",
    "    return grad, val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc420b46-9acd-4eae-8a67-734e031b39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 3. Training combined (social + separation) k-means\n",
    "# ------------------------------------------------\n",
    "\n",
    "def train_combined_kmeans(\n",
    "    X, XA, XB, k,\n",
    "    alpha=0.5,            # weight for social term  (+ alpha * max(LA, LB))\n",
    "    beta=0.5,             # weight for separation   (- beta  * min(cfdA, cfdB))\n",
    "    seeds=range(10),\n",
    "    iters=500,\n",
    "    lr=0.5,\n",
    "    verbose=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train the combined Separation–Social Fair k-means:\n",
    "\n",
    "      objective = kmeans\n",
    "                  + alpha * max(L_A, L_B)      (social fairness)\n",
    "                  - beta  * min(cfd_A, cfd_B)  (separation fairness)\n",
    "\n",
    "    We run multiple seeds and return a list of histories, one per seed.\n",
    "    \"\"\"\n",
    "    inA, inB = _group_masks_from_sets(X, XA, XB)\n",
    "    N, D = X.shape\n",
    "    history = []\n",
    "\n",
    "    for seed in seeds:\n",
    "        rng = np.random.default_rng(seed)\n",
    "        C = X[rng.choice(N, size=k, replace=False)].copy()\n",
    "\n",
    "        for t in range(iters):\n",
    "            a, _ = _assign(X, C)\n",
    "\n",
    "            # k-means term\n",
    "            g_km, _, _ = _kmeans_grad(X, C, a)\n",
    "            km_val = np.mean(np.sum((X - C[a]) ** 2, axis=1))\n",
    "\n",
    "            # social term: LA, LB (group-wise k-means loss)\n",
    "            gA, LA = _group_kmeans_grad(X, C, a, inA)\n",
    "            gB, LB = _group_kmeans_grad(X, C, a, inB)\n",
    "            if LA >= LB:\n",
    "                g_social, social_val = gA, LA\n",
    "            else:\n",
    "                g_social, social_val = gB, LB\n",
    "\n",
    "            # separation term: cfdA, cfdB (hyperplane distances)\n",
    "            g_sep_A, cfdA = _separation_grad_for_group(X[inA], C)\n",
    "            g_sep_B, cfdB = _separation_grad_for_group(X[inB], C)\n",
    "            if cfdA <= cfdB:\n",
    "                g_sep, sep_val = g_sep_A, cfdA\n",
    "            else:\n",
    "                g_sep, sep_val = g_sep_B, cfdB\n",
    "\n",
    "            # gradient descent step\n",
    "            C -= lr * (g_km + alpha * g_social - beta * g_sep)\n",
    "\n",
    "            if verbose and (t % 50 == 0 or t == iters - 1):\n",
    "                E = km_val + alpha * social_val - beta * sep_val\n",
    "                print(\n",
    "                    f\"[seed {seed:02d} | it {t:04d}] \"\n",
    "                    f\"E={E:.6f}  km={km_val:.6f}  soc={social_val:.6f}  sep={sep_val:.6f}\"\n",
    "                )\n",
    "\n",
    "        # final values for this seed\n",
    "        a, _ = _assign(X, C)\n",
    "        km_final = np.mean(np.sum((X - C[a]) ** 2, axis=1))\n",
    "        _, LA = _group_kmeans_grad(X, C, a, inA)\n",
    "        _, LB = _group_kmeans_grad(X, C, a, inB)\n",
    "        _, cfdA = _separation_grad_for_group(X[inA], C)\n",
    "        _, cfdB = _separation_grad_for_group(X[inB], C)\n",
    "\n",
    "        history.append(dict(\n",
    "            seed=seed,\n",
    "            centers=C.copy(),\n",
    "            assignments=a.copy(),\n",
    "            kmeans=km_final,\n",
    "            social_max=max(LA, LB),\n",
    "            separation_min=min(cfdA, cfdB),\n",
    "            LA=LA, LB=LB,\n",
    "            cfdA=cfdA, cfdB=cfdB,\n",
    "            social_gap=abs(LA - LB),\n",
    "            separation_gap=abs(cfdA - cfdB),\n",
    "            objective=km_final + alpha * max(LA, LB) - beta * min(cfdA, cfdB),\n",
    "        ))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40b4f95a-380d-4b25-bc52-77266a519d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 4. Full pipeline for one dataset\n",
    "# ------------------------------------------------\n",
    "\n",
    "def run_separation_social_pipeline(\n",
    "    dataset_name: str,\n",
    "    lambda_list=None,\n",
    "    seeds=range(10),\n",
    "    iters=500,\n",
    "    lr=0.5,\n",
    "    save_dir=\"./plots\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the combined Separation–Social Fair k-means on one dataset\n",
    "    for multiple λ values.\n",
    "\n",
    "    For each λ:\n",
    "      alpha = beta = λ / 2\n",
    "\n",
    "    Returns:\n",
    "      df_lam: DataFrame of aggregated metrics across seeds.\n",
    "      cfg   : dataset configuration.\n",
    "    \"\"\"\n",
    "    if lambda_list is None:\n",
    "        lambda_list = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "    X_input, XA, XB, cfg = load_dataset(dataset_name)\n",
    "    k = cfg[\"k\"]\n",
    "    tag = cfg[\"tag\"]\n",
    "\n",
    "    rows = []\n",
    "    for lam in lambda_list:\n",
    "        print(f\"\\n=== {dataset_name} | λ = {lam} ===\")\n",
    "        hist = train_combined_kmeans(\n",
    "            X_input, XA, XB, k,\n",
    "            alpha=lam / 2.0,\n",
    "            beta=lam / 2.0,\n",
    "            seeds=seeds,\n",
    "            iters=iters,\n",
    "            lr=lr,\n",
    "            verbose=False,\n",
    "        )\n",
    "\n",
    "        def agg(key):\n",
    "            vals = np.asarray([d[key] for d in hist], float)\n",
    "            return vals.mean(), vals.std()\n",
    "\n",
    "        km_m, km_s           = agg(\"kmeans\")\n",
    "        soc_m, soc_s         = agg(\"social_max\")\n",
    "        sep_m, sep_s         = agg(\"separation_min\")\n",
    "        obj_m, obj_s         = agg(\"objective\")\n",
    "        sg_m, sg_s           = agg(\"social_gap\")\n",
    "        sep_gap_m, sep_gap_s = agg(\"separation_gap\")\n",
    "\n",
    "        rows.append({\n",
    "            \"lambda\": lam,\n",
    "            \"kmeans_mean\": km_m,        \"kmeans_std\": km_s,\n",
    "            \"social_mean\": soc_m,       \"social_std\": soc_s,\n",
    "            \"separation_mean\": sep_m,   \"separation_std\": sep_s,\n",
    "            \"objective_mean\": obj_m,    \"objective_std\": obj_s,\n",
    "            \"social_gap_mean\": sg_m,    \"social_gap_std\": sg_s,\n",
    "            \"sep_gap_mean\": sep_gap_m,  \"sep_gap_std\": sep_gap_s,\n",
    "        })\n",
    "\n",
    "    df_lam = pd.DataFrame(rows).sort_values(\"lambda\").reset_index(drop=True)\n",
    "    pd.options.display.float_format = \"{:,.6f}\".format\n",
    "\n",
    "    print(df_lam[[\n",
    "        \"lambda\", \"kmeans_mean\", \"social_mean\",\n",
    "        \"separation_mean\", \"objective_mean\",\n",
    "        \"social_gap_mean\", \"sep_gap_mean\"\n",
    "    ]])\n",
    "\n",
    "    # Save numeric results\n",
    "    Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    out_csv = Path(save_dir) / f\"lambda_sweep_results_with_gaps_{tag}.csv\"\n",
    "    df_lam.to_csv(out_csv, index=False)\n",
    "    print(f\"[saved] {out_csv}\")\n",
    "\n",
    "    # Make plots\n",
    "    plot_separation_social_metrics(df_lam, lambda_list, tag, save_dir)\n",
    "\n",
    "    return df_lam, cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45f23721-d66a-415f-8c7f-1f43a8832d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# 5. Plotting\n",
    "# ------------------------------------------------\n",
    "\n",
    "def lam_label(l):\n",
    "    s = f\"{l:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "    return r\"$\\lambda$=\" + s\n",
    "\n",
    "\n",
    "def plot_separation_social_metrics(df_lam, lambda_list, tag, save_dir=\"./plots\"):\n",
    "    \"\"\"Create the same four plots as in your original notebook.\"\"\"\n",
    "    save_dir = Path(save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    all_lams = sorted(lambda_list)\n",
    "    tick_pos = np.arange(1, 1 + len(all_lams))\n",
    "    tick_labels = [lam_label(l) for l in all_lams]\n",
    "\n",
    "    # ----- 1. KMeans Loss vs lambda -----\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.errorbar(\n",
    "        tick_pos,\n",
    "        df_lam[\"kmeans_mean\"],\n",
    "        yerr=df_lam[\"kmeans_std\"],\n",
    "        marker=\"o\",\n",
    "        fmt=\"-o\",\n",
    "        capsize=4,\n",
    "        color=\"green\",\n",
    "        linewidth=3,\n",
    "    )\n",
    "    plt.ylabel(\"KMeans Loss\", fontsize=20)\n",
    "    plt.xticks(tick_pos, tick_labels, rotation=45, ha=\"right\", fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    fname = save_dir / f\"plot_kmeans_vs_lambda_{tag}.pdf\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")\n",
    "\n",
    "    # ----- 2. Social term (max(LA, LB)) -----\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.errorbar(\n",
    "        tick_pos,\n",
    "        df_lam[\"social_mean\"],\n",
    "        yerr=df_lam[\"social_std\"],\n",
    "        marker=\"o\",\n",
    "        linewidth=3,\n",
    "    )\n",
    "    plt.ylabel(\"Max Fair (Social)\", fontsize=20)\n",
    "    plt.xticks(tick_pos, tick_labels, rotation=45, ha=\"right\", fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    fname = save_dir / f\"plot_social_vs_lambda_{tag}.pdf\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")\n",
    "\n",
    "    # ----- 3. Separation term (min(cfdA, cfdB)) -----\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.errorbar(\n",
    "        tick_pos,\n",
    "        df_lam[\"separation_mean\"],\n",
    "        yerr=df_lam[\"separation_std\"],\n",
    "        marker=\"o\",\n",
    "        linewidth=3,\n",
    "        color=\"red\",\n",
    "    )\n",
    "    plt.ylabel(\"Min Fair (Separation)\", fontsize=20)\n",
    "    plt.xticks(tick_pos, tick_labels, rotation=45, ha=\"right\", fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.tight_layout()\n",
    "    fname = save_dir / f\"plot_separation_vs_lambda_{tag}.pdf\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")\n",
    "\n",
    "    # ----- 4. Fairness gaps (social vs separation) -----\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.errorbar(\n",
    "        tick_pos,\n",
    "        df_lam[\"social_gap_mean\"],\n",
    "        yerr=df_lam[\"social_gap_std\"],\n",
    "        marker=\"o\",\n",
    "        linewidth=3,\n",
    "        label=\"Social Fair\",\n",
    "        color=\"purple\",\n",
    "    )\n",
    "    plt.errorbar(\n",
    "        tick_pos,\n",
    "        df_lam[\"sep_gap_mean\"],\n",
    "        yerr=df_lam[\"sep_gap_std\"],\n",
    "        marker=\"o\",\n",
    "        linewidth=3,\n",
    "        label=\"Separation Fair\",\n",
    "        color=\"orange\",\n",
    "    )\n",
    "    plt.ylabel(\"Fairness Difference\", fontsize=20)\n",
    "    plt.xticks(tick_pos, tick_labels, rotation=45, ha=\"right\", fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fname = save_dir / f\"plot_fairness_gaps_vs_lambda_{tag}.pdf\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"[saved] {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b9bcc-26ef-4b80-9898-c87288a1c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[adult] n = 1000\n",
      "[adult] |A| = 656, |B| = 344\n",
      "\n",
      "=== adult | λ = 0.0 ===\n",
      "\n",
      "=== adult | λ = 0.2 ===\n",
      "\n",
      "=== adult | λ = 0.4 ===\n",
      "\n",
      "=== adult | λ = 0.6 ===\n",
      "\n",
      "=== adult | λ = 0.8 ===\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------\n",
    "# 6. Example: run for one dataset\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Choose one of: \"adult\", \"credit\", \"bank\", \"student\"\n",
    "dataset_name = \"adult\"\n",
    "\n",
    "df_lam, cfg = run_separation_social_pipeline(\n",
    "    dataset_name=dataset_name,\n",
    "    lambda_list=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    seeds=range(10),\n",
    "    iters=500,\n",
    "    lr=0.5,\n",
    "    save_dir=f\"./plots/combined_{dataset_name}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
